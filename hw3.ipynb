{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import re\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings matrix and an embedding dictionary\n",
    "word_embeddings,embedding_dict, hidden_size = load_embeddings('../glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"../SRLData/EN/CoNLL2009-ST-English-train.txt\"\n",
    "path_dev = \"../SRLData/EN/CoNLL2009-ST-English-development.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "tr_raw_sentences = read_conll(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate encoders for POS and ARGS\n",
    "pos_tags,pos_tag_encoder = list_pos_tags(tr_raw_sentences)\n",
    "args, args_encoder = list_args(tr_raw_sentences)\n",
    "\n",
    "args_classes = len(args)\n",
    "null_code = args_encoder.transform(['_'])[0] #No classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicate-centered sentences / Windowing\n",
    "left_words = 20\n",
    "right_words = 10\n",
    "window_span = [left_words,right_words]\n",
    "sentence_length = left_words + right_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate inputs for the network \n",
    "tr_sentences,tr_pred_inds = generate_inputs(tr_raw_sentences,embedding_dict,pos_tag_encoder,window_span)\n",
    "tr_labels,tr_missed = generate_labels(tr_raw_sentences,args_encoder,window_span)\n",
    "\n",
    "# Padding\n",
    "tr_sentences,tr_lens = pad(tr_sentences,max_length = sentence_length)\n",
    "tr_labels,_ = pad(tr_labels,max_length = sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development data\n",
    "dev_raw_sentences = read_conll(path_dev)\n",
    "\n",
    "dev_sentences,dev_pred_inds = generate_inputs(dev_raw_sentences,embedding_dict,pos_tag_encoder,window_span)\n",
    "dev_labels,dev_missed = generate_labels(dev_raw_sentences,args_encoder,window_span)\n",
    "\n",
    "dev_sentences, dev_lens = pad(dev_sentences,max_length = sentence_length)\n",
    "dev_labels,_ = pad(dev_labels,max_length = sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dev_raw_sentences,tr_raw_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "\n",
    "    in_sentences: Input sentences. Shape is (batch,sentence_length,2).\n",
    "    in_labels: Input labels. Shape is (batch,sentence_length)\n",
    "    in_lens: Input sentences' lengths. Shape is (batch)\n",
    "    in_pred_inds: Input predicate indexes. Shape is (batch)\n",
    "    in_prob_dropout: Input probability for dropout.\n",
    "    in_learn_rate: Input learning rate\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sentences = tf.placeholder(tf.int32, shape=[None,sentence_length,2],name='in_sentences')\n",
    "in_labels = tf.placeholder(tf.int32, shape=[None,sentence_length],name='in_labels')\n",
    "in_lens = tf.placeholder(tf.int32, shape=[None],name='in_lens')\n",
    "in_pred_inds = tf.placeholder(tf.int32,shape=[None],name='in_pred_inds')\n",
    "in_prob_dropout = tf.placeholder(tf.float32,name='in_prob_dropout')\n",
    "in_learn_rate = tf.placeholder(tf.float32,name='in_learn_rate')\n",
    "\n",
    "t_batch_size = tf.shape(in_sentences)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input assembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the sentences vector in order to place the embeddings\n",
    "# Shape is (batch,sentence_length)\n",
    "t_sentences_word_indexes = tf.squeeze(tf.slice(in_sentences,(0,0,0),(t_batch_size,sentence_length,1)),-1)\n",
    "\n",
    "embeddings = tf.Variable(word_embeddings,dtype=tf.float32,trainable=False)\n",
    "\n",
    "# Replacing the embedding values with the embeddings\n",
    "# Shape is (batch,sentence_length,hidden_size)\n",
    "t_sentences_embeddings = tf.nn.embedding_lookup(embeddings,t_sentences_word_indexes)\n",
    "\n",
    "# Slicing the sentences vector in order to get the pos values\n",
    "# Shape is (batch,sentence_length,1)\n",
    "t_sentences_word_pos = tf.cast(tf.slice(in_sentences,(0,0,1),(t_batch_size,sentence_length,1)),tf.float32)\n",
    "\n",
    "# Concatenating in order to generate the vector\n",
    "# Shape is (batch,sentence_length,hidden_size + 1)\n",
    "t_sentences = tf.concat([t_sentences_embeddings,t_sentences_word_pos],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the binary vectors to append to the sentences\n",
    "t_bin_vects = tf.one_hot(in_pred_inds,sentence_length)\n",
    "t_bin_vects = tf.expand_dims(t_bin_vects,-1)\n",
    "\n",
    "t_sentences = tf.concat([t_sentences,t_bin_vects],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_fw = tf.contrib.rnn.LSTMCell(lstm_units)\n",
    "cell_bw = tf.contrib.rnn.LSTMCell(lstm_units)\n",
    "\n",
    "# Dropout\n",
    "cell_fw = tf.nn.rnn_cell.DropoutWrapper(cell_fw, output_keep_prob=in_prob_dropout)\n",
    "cell_bw = tf.nn.rnn_cell.DropoutWrapper(cell_bw, output_keep_prob=in_prob_dropout)\n",
    "\n",
    "t_bilstm,_ = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, t_sentences,sequence_length=in_lens, dtype=tf.float32)\n",
    "\n",
    "# Concatenating the two hidden states of the BiLSTM output\n",
    "# Shape is (batch,sentence_length,lstm_units*2)\n",
    "t_bilstm = tf.concat([t_bilstm[0],t_bilstm[1]],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input assembling for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the batch_index to each predicate index (needed for gather)\n",
    "# Shape is (batch,2)\n",
    "t_pred_inds = tf.stack([tf.range(t_batch_size),in_pred_inds],axis=1)\n",
    "\n",
    "# Selecting the predicates with the right indexes. More precisely, we pick one vector from the sentence_length \n",
    "# dimension for every sentence\n",
    "# Shape is (batch,lstm_units*2)\n",
    "t_preds = tf.gather_nd(t_bilstm,t_pred_inds)\n",
    "\n",
    "# Adding the lenght dimension in order to tile\n",
    "# Shape is (batch,1,lstm_units*2)\n",
    "t_preds = tf.expand_dims(t_preds,1)\n",
    "\n",
    "# Tiling the vector predicate along the length dimension in order to concatenate\n",
    "# Shape is (batch,sentence_length,lstm_units*2)\n",
    "t_preds = tf.tile(t_preds,[1,sentence_length,1])\n",
    "\n",
    "# Concatenating along the last dimension word and predicate features\n",
    "# Shape is (batch,sentence_length,lstm_units*4)\n",
    "t_pairs = tf.concat([t_bilstm,t_preds],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a mask for the padding using the input lengths\n",
    "# Shape is (batch,sentence_length)\n",
    "t_mask = tf.sequence_mask(in_lens)\n",
    "\n",
    "# Applying the mask on the word-predicate pairs, removing spurious pairs. T is the number of times 'True' appears\n",
    "# in the mask or the sum of all lengths in in_lens.\n",
    "# Shape is (T,lstm_units*4)\n",
    "t_pairs = tf.boolean_mask(t_pairs,t_mask)\n",
    "\n",
    "# Applying the mask on the labels\n",
    "# Shape is (T)\n",
    "t_labels = tf.boolean_mask(in_labels,t_mask)\n",
    "\n",
    "# Shape of the vectors to feed to the classifier\n",
    "vect_shape = t_pairs.get_shape().as_list()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "W_f = tf.Variable(tf.truncated_normal([vect_shape,args_classes],stddev=0.1))\n",
    "b_f = tf.Variable(tf.constant(0., shape=[args_classes]))\n",
    "\n",
    "t_logits = tf.matmul(t_pairs, W_f) + b_f\n",
    "\n",
    "t_loss_roles = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=t_labels,logits=t_logits)\n",
    "t_loss_roles = tf.reduce_mean(t_loss_roles,name='t_loss_roles')\n",
    "\n",
    "t_optimizer = tf.train.AdamOptimizer(in_learn_rate).minimize(t_loss_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_roles = tf.nn.softmax(t_logits)\n",
    "t_roles = tf.argmax(t_roles,1,output_type=tf.int32)\n",
    "\n",
    "t_accuracy = tf.equal(t_roles,t_labels)\n",
    "t_accuracy = tf.reduce_mean(tf.cast(t_accuracy,tf.float32),name='t_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_writer = tf.summary.FileWriter('./summary', sess.graph)\n",
    "summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "Previous model restored.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.makedirs(\"model\")\n",
    "    \n",
    "if tf.train.checkpoint_exists('./model/model.ckpt'):\n",
    "    saver.restore(sess, './model/model.ckpt')\n",
    "    print(\"Previous model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 100\n",
    "keep_prob = 0.6\n",
    "learn_rate = 0.005\n",
    "\n",
    "batch_index = 0\n",
    "num_batches_per_epoch = ceil(len(tr_labels)/batch_size)\n",
    "n_iterations = num_batches_per_epoch*epochs\n",
    "\n",
    "# Part of training data in order to check overfitting\n",
    "\n",
    "tr_over_sentences = tr_sentences[:1000]\n",
    "tr_over_labels = tr_labels[:1000]\n",
    "tr_over_pred_inds = tr_pred_inds[:1000]\n",
    "tr_over_lens = tr_lens[:1000]\n",
    "tr_over_missed = tr_missed[:1000]\n",
    "\n",
    "# Computing the initial F1 score\n",
    "\n",
    "feed_dict = {in_sentences : dev_sentences, in_labels :dev_labels, in_pred_inds: dev_pred_inds,in_lens:dev_lens,in_prob_dropout:1}\n",
    "o_roles,o_labels = sess.run([t_roles,t_labels],feed_dict=feed_dict)\n",
    "_,_,max_f1 = compute_scores(o_roles,o_labels,null_code,dev_missed)\n",
    "\n",
    "for ite in range(n_iterations):\n",
    "    start = time.clock()\n",
    "    \n",
    "    # Batch\n",
    "    bt_sentences = tr_sentences[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "    bt_labels = tr_labels[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "    bt_pred_inds = tr_pred_inds[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "    bt_lens = tr_lens[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "    \n",
    "    batch_index = (batch_index + 1 ) % num_batches_per_epoch\n",
    "    \n",
    "    feed_dict = {in_sentences : bt_sentences, in_labels :bt_labels, in_pred_inds: bt_pred_inds,in_lens:bt_lens,in_learn_rate:learn_rate,in_prob_dropout:keep_prob}\n",
    "    sess.run(t_optimizer,feed_dict=feed_dict)\n",
    "    \n",
    "    end = time.clock()\n",
    "    \n",
    "    if ite % 10 == 0:\n",
    "        print('Iteration # ' + str(ite) + ' time: ' + str(end-start))\n",
    "        \n",
    "    if ite % 100 == 0:\n",
    "        \n",
    "        # Training data\n",
    "        feed_dict = {in_sentences : tr_over_sentences, in_labels :tr_over_labels, in_pred_inds: tr_over_pred_inds,in_lens:tr_over_lens,in_prob_dropout:1}\n",
    "        o_roles,o_labels,o_accuracy = sess.run([t_roles,t_labels,t_accuracy],feed_dict=feed_dict)\n",
    "        precision,recall,f1_score = compute_scores(o_roles,o_labels,null_code,tr_over_missed)\n",
    "        print('Train data)  Precision: ' + str(precision) + ' Recall: ' +str(recall)+ ' F1 score: '+str(f1_score) )\n",
    "        print('Train data)  Accuracy: ' + str(o_accuracy))\n",
    "        \n",
    "        # Development data\n",
    "        feed_dict = {in_sentences : dev_sentences, in_labels :dev_labels, in_pred_inds: dev_pred_inds,in_lens:dev_lens,in_prob_dropout:1}\n",
    "        o_roles,o_labels,o_accuracy = sess.run([t_roles,t_labels,t_accuracy],feed_dict=feed_dict)\n",
    "        precision,recall,f1_score = compute_scores(o_roles,o_labels,null_code,dev_missed)\n",
    "        print('Dev data)  Precision: ' + str(precision) + ' Recall: ' +str(recall)+ ' F1 score: '+str(f1_score) ,flush=True)\n",
    "        print('Dev data)  Accuracy: ' + str(o_accuracy))\n",
    "        \n",
    "        # Save weights only if the score improved\n",
    "        if f1_score >= max_f1:\n",
    "            max_f1 = f1_score\n",
    "            saver.save(sess, './model/model.ckpt')\n",
    "            print('---Weights have been saved---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Loading the weights with the highest F1 score\n",
    "saver.restore(sess, './model/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev data)  Precision: 0.8884914056365064 Recall: 0.7344392354850343 F1 score: 0.8041538340045803\n",
      "Dev data)  Accuracy: 0.966068\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {in_sentences : dev_sentences, in_labels :dev_labels, in_pred_inds: dev_pred_inds,in_lens:dev_lens,in_prob_dropout:1}\n",
    "o_roles,o_labels,o_accuracy = sess.run([t_roles,t_labels,t_accuracy],feed_dict=feed_dict)\n",
    "precision,recall,f1_score = compute_scores(o_roles,o_labels,null_code,dev_missed)\n",
    "print('Dev data)  Precision: ' + str(precision) + ' Recall: ' +str(recall)+ ' F1 score: '+str(f1_score) )\n",
    "print('Dev data)  Accuracy: ' + str(o_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_labels = args_encoder.inverse_transform(o_labels)\n",
    "o_roles = args_encoder.inverse_transform(o_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    A0    A1    A2   A3  A4  A5  AA  AM-ADV  AM-CAU  AM-DIR   ...     \\\n",
      "Actual                                                                 ...      \n",
      "A0         2630   143    24    5   0   0   0       0       0       0   ...      \n",
      "A1          101  4228    52   14   1   0   0       0       0       1   ...      \n",
      "A2           32   156  1027    6   4   0   0       1       0       2   ...      \n",
      "A3           16    21    16  162   0   0   0       0       0       0   ...      \n",
      "A4            0     7     9    3  46   0   0       0       0       1   ...      \n",
      "A5            0     1     2    0   0   0   0       0       0       0   ...      \n",
      "AA            1     0     0    0   0   0   0       0       0       0   ...      \n",
      "AM-ADV        0     2     1    0   0   0   0     105       0       0   ...      \n",
      "AM-CAU        0     1     1    0   1   0   0       0      20       0   ...      \n",
      "AM-DIR        0     3     6    0   1   0   0       0       0      17   ...      \n",
      "AM-DIS        0     0     1    0   0   0   0      10       0       0   ...      \n",
      "AM-EXT        0     3     0    0   0   0   0       4       0       0   ...      \n",
      "AM-LOC        9    18    21    0   0   0   0       1       0       1   ...      \n",
      "AM-MNR        3    18    24    3   1   0   0      11       0       1   ...      \n",
      "AM-MOD        0     0     0    0   0   0   0       0       0       0   ...      \n",
      "AM-NEG        0     0     0    0   0   0   0       0       0       0   ...      \n",
      "AM-PNC        0     6     9    3   1   0   0       1       1       0   ...      \n",
      "AM-PRD        0     0     0    0   0   0   0       0       0       0   ...      \n",
      "AM-TMP        0    19     2    1   0   0   0       7       0       0   ...      \n",
      "C-A1          0    13     3    0   0   0   0       0       0       0   ...      \n",
      "C-A2          0     0     0    0   0   0   0       1       0       0   ...      \n",
      "C-AM-CAU      0     0     0    0   0   0   0       0       1       0   ...      \n",
      "C-AM-DIR      0     0     0    0   0   0   0       0       0       1   ...      \n",
      "C-AM-MNR      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-A0          1     1     0    0   0   0   0       0       0       0   ...      \n",
      "R-A1          0     1     0    0   0   0   0       0       0       0   ...      \n",
      "R-A2          0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-AM-CAU      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-AM-EXT      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-AM-LOC      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-AM-MNR      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "R-AM-TMP      0     0     0    0   0   0   0       0       0       0   ...      \n",
      "_           341   460   123   17   5   1   0      31       3       2   ...      \n",
      "__all__    3134  5101  1321  214  60   1   0     172      25      26   ...      \n",
      "\n",
      "Predicted  R-A0  R-A1  R-A2  R-AM-CAU  R-AM-EXT  R-AM-LOC  R-AM-MNR  R-AM-TMP  \\\n",
      "Actual                                                                          \n",
      "A0            0     0     0         0         0         0         0         0   \n",
      "A1            0     1     0         0         0         0         0         0   \n",
      "A2            0     1     0         0         0         0         0         0   \n",
      "A3            0     0     0         0         0         0         0         0   \n",
      "A4            0     0     0         0         0         0         0         0   \n",
      "A5            0     0     0         0         0         0         0         0   \n",
      "AA            0     0     0         0         0         0         0         0   \n",
      "AM-ADV        0     0     0         0         0         0         0         0   \n",
      "AM-CAU        0     0     0         0         0         0         0         0   \n",
      "AM-DIR        0     0     0         0         0         0         0         0   \n",
      "AM-DIS        0     0     0         0         0         0         0         0   \n",
      "AM-EXT        0     0     0         0         0         0         0         0   \n",
      "AM-LOC        0     0     0         0         0         1         0         0   \n",
      "AM-MNR        0     0     0         0         0         0         0         0   \n",
      "AM-MOD        0     0     0         0         0         0         0         0   \n",
      "AM-NEG        0     0     0         0         0         0         0         0   \n",
      "AM-PNC        0     0     0         0         0         0         0         0   \n",
      "AM-PRD        0     0     0         0         0         0         0         0   \n",
      "AM-TMP        0     0     0         0         0         0         0         0   \n",
      "C-A1          0     0     0         0         0         0         0         0   \n",
      "C-A2          0     0     0         0         0         0         0         0   \n",
      "C-AM-CAU      0     0     0         0         0         0         0         0   \n",
      "C-AM-DIR      0     0     0         0         0         0         0         0   \n",
      "C-AM-MNR      0     0     0         0         0         0         0         0   \n",
      "R-A0        127     3     0         0         0         0         0         0   \n",
      "R-A1          0    72     0         0         0         0         0         0   \n",
      "R-A2          0     1     3         0         0         0         0         0   \n",
      "R-AM-CAU      0     0     0         1         0         0         0         0   \n",
      "R-AM-EXT      0     0     0         0         0         0         0         0   \n",
      "R-AM-LOC      0     0     0         0         0         7         0         0   \n",
      "R-AM-MNR      0     0     0         0         0         1         1         0   \n",
      "R-AM-TMP      0     0     0         0         0         0         0        17   \n",
      "_            11     9     0         0         0         4         1         9   \n",
      "__all__     138    87     3         1         0        13         2        26   \n",
      "\n",
      "Predicted       _  __all__  \n",
      "Actual                      \n",
      "A0            551     3363  \n",
      "A1            684     5112  \n",
      "A2            288     1566  \n",
      "A3             75      297  \n",
      "A4             11       82  \n",
      "A5              0        3  \n",
      "AA              0        1  \n",
      "AM-ADV         96      235  \n",
      "AM-CAU         15       41  \n",
      "AM-DIR          6       34  \n",
      "AM-DIS         46      195  \n",
      "AM-EXT          9       47  \n",
      "AM-LOC         81      330  \n",
      "AM-MNR        109      420  \n",
      "AM-MOD         12      314  \n",
      "AM-NEG          8      123  \n",
      "AM-PNC         18       71  \n",
      "AM-PRD          1        2  \n",
      "AM-TMP        172      828  \n",
      "C-A1           35      133  \n",
      "C-A2            1        2  \n",
      "C-AM-CAU        0        1  \n",
      "C-AM-DIR        0        1  \n",
      "C-AM-MNR        2        2  \n",
      "R-A0           12      144  \n",
      "R-A1            9       82  \n",
      "R-A2            1        5  \n",
      "R-AM-CAU        2        3  \n",
      "R-AM-EXT        1        1  \n",
      "R-AM-LOC        2        9  \n",
      "R-AM-MNR        4        6  \n",
      "R-AM-TMP       14       31  \n",
      "_          120184   121462  \n",
      "__all__    122449   134946  \n",
      "\n",
      "[34 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas_ml/confusion_matrix/abstract.py:66: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  df = df.loc[idx, idx.copy()].fillna(0)  # if some columns or rows are missing\n"
     ]
    }
   ],
   "source": [
    "conf_matr = ConfusionMatrix(o_labels,o_roles)\n",
    "print(conf_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         A0       0.84      0.78      0.81      3363\n",
      "         A1       0.83      0.83      0.83      5112\n",
      "         A2       0.78      0.66      0.71      1566\n",
      "         A3       0.76      0.55      0.63       297\n",
      "         A4       0.77      0.56      0.65        82\n",
      "         A5       0.00      0.00      0.00         3\n",
      "         AA       0.00      0.00      0.00         1\n",
      "     AM-ADV       0.61      0.45      0.52       235\n",
      "     AM-CAU       0.80      0.49      0.61        41\n",
      "     AM-DIR       0.65      0.50      0.57        34\n",
      "     AM-DIS       0.77      0.67      0.72       195\n",
      "     AM-EXT       0.81      0.53      0.64        47\n",
      "     AM-LOC       0.64      0.58      0.60       330\n",
      "     AM-MNR       0.69      0.55      0.61       420\n",
      "     AM-MOD       0.96      0.96      0.96       314\n",
      "     AM-NEG       0.97      0.91      0.94       123\n",
      "     AM-PNC       0.54      0.45      0.49        71\n",
      "     AM-PRD       1.00      0.50      0.67         2\n",
      "     AM-TMP       0.81      0.74      0.77       828\n",
      "       C-A1       0.91      0.62      0.74       133\n",
      "       C-A2       0.00      0.00      0.00         2\n",
      "   C-AM-CAU       0.00      0.00      0.00         1\n",
      "   C-AM-DIR       0.00      0.00      0.00         1\n",
      "   C-AM-MNR       0.00      0.00      0.00         2\n",
      "       R-A0       0.92      0.88      0.90       144\n",
      "       R-A1       0.83      0.88      0.85        82\n",
      "       R-A2       1.00      0.60      0.75         5\n",
      "   R-AM-CAU       1.00      0.33      0.50         3\n",
      "   R-AM-EXT       0.00      0.00      0.00         1\n",
      "   R-AM-LOC       0.54      0.78      0.64         9\n",
      "   R-AM-MNR       0.50      0.17      0.25         6\n",
      "   R-AM-TMP       0.65      0.55      0.60        31\n",
      "          _       0.98      0.99      0.99    121462\n",
      "\n",
      "avg / total       0.96      0.97      0.97    134946\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karapost/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(o_labels,o_roles)\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../TestData/test.csv'\n",
    "path_output_test = '../TestData/test_with_args.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_sentences = read_conll(path_test)\n",
    "\n",
    "test_sentences,test_pred_inds = generate_inputs(test_raw_sentences,embedding_dict,pos_tag_encoder,window_span)\n",
    "test_sentences,test_lens = pad(test_sentences,max_length=sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "feed_dict = {in_sentences : test_sentences, in_pred_inds: test_pred_inds,in_lens:test_lens,in_prob_dropout:1}\n",
    "o_roles = sess.run(t_roles,feed_dict=feed_dict)\n",
    "\n",
    "# Adding labels\n",
    "add_labels(test_raw_sentences,o_roles,window_span,args_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a file\n",
    "write_labels_conll('../TestData/test.csv','../TestData/test_with_args.csv',test_raw_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
